{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "48d09f66",
   "metadata": {},
   "source": [
    "# GPT-J-6B Serving with Ray AIR\n",
    "\n",
    "In this example, we will showcase how to use the Ray AIR for GPT-J serving (online inference). GPT-J is a GPT-2-like causal language model trained in our previous step\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cec76ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install \"ray[air]\" boto3 \"ray\"\n",
    "! pip install \"datasets\" \"evaluate\" \"accelerate==0.20.3\" \"transformers>=4.26.0\" \"torch>=1.12.0\" \"deepspeed==0.8.3\"\n",
    "! pip install -U protobuf==3.19.6 xgboost==1.3.3 xgboost-ray==0.1.15 pandas==1.5.3 tensorboard\n",
    "! pip install pandas --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da577057",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import ray\n",
    "import boto3\n",
    "from ray import serve\n",
    "from ray.serve.http_adapters import pandas_read_json\n",
    "from ray.train.huggingface import TransformersPredictor\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bbb3b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "ray.init(\n",
    "    address=\"ray://ray-cluster-serve-kuberay-head-svc.ray-cluster-serve.svc.cluster.local:10001\",\n",
    "    namespace=\"serve\",\n",
    "    runtime_env={\n",
    "        \"pip\": [\n",
    "            \"datasets\",\n",
    "            \"evaluate\",\n",
    "            # Latest combination of accelerate==0.19.0 and transformers==4.29.0\n",
    "            # seems to have issues with DeepSpeed process group initialization,\n",
    "            # and will result in a batch_size validation problem.\n",
    "            # TODO(jungong) : get rid of the pins once the issue is fixed.\n",
    "            \"accelerate==0.20.3\",\n",
    "            \"transformers==4.26.0\",\n",
    "            \"torch>=1.12.0\",\n",
    "        ]\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d66bf12f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start Serve\n",
    "serve.start(detached=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99b69211",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3 = boto3.client(\"s3\")\n",
    "bucket = \"fm-ops-datasets\"\n",
    "model_key = \"checkpoints/TransformersTrainer_2023-09-05_12-25-24/TransformersTrainer_f638a_00000_0_2023-09-05_12-25-24/checkpoint_000000/pytorch_model.bin\"\n",
    "tokenizer_key = \"checkpoints/TransformersTrainer_2023-09-05_12-25-24/TransformersTrainer_f638a_00000_0_2023-09-05_12-25-24/checkpoint_000000/tokenizer.json\"\n",
    "config_json_key = \"checkpoints/TransformersTrainer_2023-09-05_12-25-24/TransformersTrainer_f638a_00000_0_2023-09-05_12-25-24/checkpoint_000000/config.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a3aeab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"local_model\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca1c2efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3.download_file(bucket, model_key, \"local_model/pytorch_model.bin\")\n",
    "s3.download_file(bucket, tokenizer_key, \"local_model/tokenizer.json\")\n",
    "s3.download_file(bucket, config_json_key, \"local_model/config.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5034f353",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load tokenizer and model\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"local_model\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"local_model\").cuda()  # Move model to GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a39f404",
   "metadata": {},
   "outputs": [],
   "source": [
    "ray.shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e729a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# serve.get_deployment(\"default_XGBoostService\").url\n",
    "serve.delete(\"default\")\n",
    "serve.shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bebb62d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ray.job_submission import JobSubmissionClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ec2f7b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ray_client = JobSubmissionClient(\"http://ray-cluster-serve-kuberay-head-svc.ray-cluster-serve.svc.cluster.local:8265\")\n",
    "\n",
    "ray_serving = (\n",
    "    \"rm -rf fm-ops-eks && git clone https://github.com/lusoal/fm-ops-eks || true;\"\n",
    "    \"chmod +x fm-ops-eks/scripts/serve_gptj.py && python fm-ops-eks/scripts/serve_gptj.py\"\n",
    ")\n",
    "\n",
    "submission_id = ray_client.submit_job(\n",
    "    entrypoint=ray_serving,\n",
    "    runtime_env={\"pip\": [\"boto3\"]},\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
